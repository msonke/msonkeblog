# The AI Revolution is Largely Overblown

## Artificial Implications

It's very easy to get caught up in the idea of AI that is sold to the public.  What becomes incredibly clear is that most individuals that tend to speak with authority about AI also haven't the slightest idea of what's going on behind the scenes.

Clearly the invention of AI in it's current state is indeed groundbreaking, and will absolutely help increase productivity in many sectors across the board, but how this is playing out in real-terms is largely reminiscent of the dotcom bubble.  Just as was the case during that time, when .com prices were speculatively priced like dutch tulips and subsequently came crashing down when the true value of a domain name was realized, we are witnessing the same type of mania surrounding an arguably more advanced technology that is even more misunderstood than a DNS server was in that era.

Language Models and Generative AI have definitely made an impact on the way we work already, allowing workers to interact with a virtual assistant that can create ideas, images, and even code.  This seemingly gives access to skills that would have been previously inaccessable to other professions, and can clearly save vast amounts of time when used properly.  This is not overblown, and it definitely has found it's place already in society.

## True Understanding

Very early in my development journey I decided to look up AI and Machine Learning myself, although at the time it was considerably different.  The goal was to create an AI based trading bot, one that I could harness my knowledge of Financial markets I've built over the years and take advantage of the market inefficiencies in an automated fashion.  This was a noble goal, although the realities of the scope of such a project set in and other tasks began to take priority, the technology behind AI was easy enough to understand, but clearly very difficult to implement.

You see, when programming with AI there are alot of assumptions that are made, and in fact there are large pitfalls you can run across when developing AI.  One of the most prevalent problems is blind trust in the results.

There are certain things that AI is great at, but at it's core you'll find a statistically based algorithm that analyzes the likelyhood of many different scenarios in order to make an informed decision based on odds.  There are varying methods to accomplish this, all with their own pros and cons, but one of the most popular models is XGBoost or LLM, both with different goals utilizing similar underlying tech.  Understanding thistech at its core is essential to understanding how limited AI in its current form is.

## Oversold

The term artificial intelligence is misleading.  It's been used for years as the concept of something similar to a human brain for automatons and technology.  In actuality it's an educated guessing machine at best.  You see, one of the core problems and the illusions of AI, is that it needs to be understood that it is a knowledge <em>aggregator</em> not a knowledge <em>creator.</em>  Meaning any response you are given, art that is generative, or decision made is only a derivative response comprised of the analysis of other already existing ideas that it contains in its dataset.  Simply put, none of the work it provides by very definition can be novel, because they are already based on other works.

There is a worse problem here, though, than the illusion of original thought.  That is blind trust in a statistical model.

What the media and overhyped investors fail to recognize, is vast number of responses provided by LLM are wrong.  However, they are almost always blindly followed as fact, which anyone who truly understand the technology knows is frequently incorrect.

There is no denying that there is some value for a tool that can provide you with boilerplate code.  The time savings are immense, and well worth it for those who decide to use it.  One bug or security flaw, and the opinion about its effectiveness changes drastically.  Indeed, when you see the problem from this lens, it becomes quite clear why things have quickly becomes overblown.

How much value do you have for an assistant that frequently provides you the wrong answers, so much that you spend as much time if not more scrutinizing the answers when you more than likely would have been better off researching and understanding the topic yourself?  Aside from the aforementioned time savings with boilerplate code, the usefulness for AI beyond this is quite unclear.

In fact, many times the same AI that has been heralded to bring the end of development jobs globally cannot even do simple arithmetic.  They are easily influenced, and can be subject to new attack vectors such as data poisoning and prompt manipulation.  The blind trust that many put in these AI models have introduced huge amounts of inefficient and vulnerable code, making things even worse as the answers are most always taken verbatim and not verified for accuracy.  When this is taken into account, the time savings become more and more negligible.

## Someone still needs to prompt...

I'm not sure it hasn't been realized that AI could never fully replace developers because quite simply they cannot prompt themselves.  Even if someone uses a prompt to generate terrible code through AI, there's still a human doing the prompting and most likely there always will be.  The question then shifts more towards what's really needed in terms of human capital.

Stated another way, is there going to be a high demand for people who know how to prompt?  This is a low-value skill, as quite honestly anyone with a little effort can become an effective prompter in no time flat.  It is telling that almost immediately there was a rise and fall of the position of AI promptor.  This is not what's needed, because where the true power in AI prompting is when the prompting is done by someone who understands the underlying technologies used in the AI generated answer enough to be able to audit the code given, rather than trusting it blindly.

Ironically, while most seem to believe this will lead to job losses for developers to AI that can seemingly code, the reality is that it will more likely result in <em>more</em> demand for developers, and the reasons are twofold.

In addition to the need for quality code auditors that can correct AI generated code, there is also a large need for AI and ML developers now, much more than existed before.  It's clear that the misunderstanding of these concepts have lead businesses to believe they will be able to drastically cut their workforce, while experienced developers most likely could compare it to a framework that helps develop code in a more efficient manner.  The tragedy is that many managers that specialize in managing people lack the understanding of the tech, and as a result make poor business decisions by forcing AI to take a role it's not suited to; it can never replace a human developer.

## Other industries

There is something to be said that although tech is seemingly addressing these potential issues first as it is incorporated into everyday life, other industries truly are at risk of being replaced.  Writers and copywriters in particular seem to be at risk of displacement, as even though there is something to be said also about the quality of writing of an AI as opposed to a human, the difference here is much more negligible than those in tech.  It might happen that something similar happen in this field, where the prompter is simply an editor that uses AI to quickly generate content which is then slightly altered to reflect the author's tone.

Perhaps the most intriguing potential when it comes to AI comes from it's ability to be combined with automation.  Automation easily has the potential to displace many of the manual manufacturing jobs we see today, and has been trending towards this end for the past few decades.  One only has to look towards examples like Tesla's Gigafactories to know this to be true.  The full effects of AI will take time to be felt through implementation, but it still remains to be seen the true impact it will have on the manufacturing industry as a whole.

## Conclusion

The running joke is that developers are glad that AI is taking their job, and in many ways that's true.  Boilerplate code is the least interesting aspect of development, and AI largely frees the developer to think about code at a higher level and in a much more granule level than without.  This is it's true power, allowing developers to focus on what truly makes them valuable and less of the monotonous tasks that can be easily outsourced.

There is no doubt AI will be a disruptive technology, but the severe limitations that arise due to the core of the technology should temper any expectations that mass amounts of people will be upended from losing their jobs to it.  Sooner or later I'm sure it will be come clear what exactly the value is of an assistant that is confidently wrong on a routine basis really is.
